{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highrise FAQ Chatbot Development Notebook\n",
    "This notebook implements a RAG-based chatbot for Highrise FAQ using:\n",
    "- LangChain\n",
    "- Google's Generative AI (Gemini)\n",
    "- MongoDB Atlas Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "Setup environment and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from pymongo import MongoClient\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_mongodb.vectorstores import MongoDBAtlasVectorSearch\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_to_documents(json_data):\n",
    "    \"\"\"\n",
    "    Convert JSON FAQ data into Langchain Documents format\n",
    "    \n",
    "    Args:\n",
    "        json_data (dict): Raw JSON data containing FAQ collections\n",
    "        \n",
    "    Returns:\n",
    "        list: List of Langchain Document objects\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    if \"collections\" in json_data:\n",
    "        for collection in json_data[\"collections\"]:\n",
    "            for article in collection.get(\"articles\", []):\n",
    "                content = f\"{article.get('question', '')}\\n {article.get('answer', '')}\\n\"\n",
    "                doc = Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\"source\": article.get(\"url\", \"unknown\")},\n",
    "                )\n",
    "                documents.append(doc)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vector_store(faq_file: str, connection_string: str):\n",
    "    \"\"\"\n",
    "    Initialize MongoDB Atlas Vector Store with FAQ data\n",
    "    \n",
    "    Args:\n",
    "        faq_file (str): Path to FAQ JSON file\n",
    "        connection_string (str): MongoDB connection URI\n",
    "        \n",
    "    Returns:\n",
    "        MongoDBAtlasVectorSearch: Initialized vector store\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize embeddings\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "        \n",
    "        # Load and process documents\n",
    "        if not os.path.exists(faq_file):\n",
    "            raise FileNotFoundError(f\"FAQ file not found: {faq_file}\")\n",
    "            \n",
    "        with open(faq_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            faq_data = json.load(f)\n",
    "            \n",
    "        documents = parse_json_to_documents(faq_data)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=150\n",
    "        )\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Configure MongoDB\n",
    "        client = MongoClient(connection_string)\n",
    "        DB_NAME = \"langchain_faq_db_test\"\n",
    "        COLLECTION_NAME = \"langchain_faq_vectorstores_test\"\n",
    "        ATLAS_VECTOR_SEARCH_INDEX_NAME = \"langchain-faq-index-vectorstores_test\"\n",
    "        MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]\n",
    "        \n",
    "        # Initialize vector store\n",
    "        vector_store = MongoDBAtlasVectorSearch.from_documents(\n",
    "            documents=docs,\n",
    "            collection=MONGODB_COLLECTION,\n",
    "            embedding=embeddings,\n",
    "            index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "            relevance_score_fn=\"cosine\",\n",
    "        )\n",
    "        vector_store.create_vector_search_index(dimensions=768)\n",
    "        logging.info(f\"Vector store initialized with {len(docs)} documents.\")\n",
    "        return vector_store\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during vector store initialization: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup & Initialize Vector Store\n",
    "Set required environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your-api-key\"\n",
    "connection_string = \"your mongodb connection string\"\n",
    "faq_file = \"faq_data.json\"\n",
    "vector_store = initialize_vector_store(faq_file, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_retrieval_chain(vector_store):\n",
    "    \"\"\"\n",
    "    Set up the retrieval-augmented generation chain\n",
    "    \n",
    "    Args:\n",
    "        vector_store: Initialized vector store\n",
    "    \n",
    "    Returns:\n",
    "        Chain: Configured RAG chain\n",
    "    \"\"\"\n",
    "    # Configure retriever\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\", \n",
    "        search_kwargs={\"k\": 6}\n",
    "    )\n",
    "    \n",
    "    # Define system prompt\n",
    "    system_prompt = (\n",
    "            \"\"\"\n",
    "                You are an AI assistant designed to answer questions based on specific context provided from the Highrise FAQ. Your role is to help users by giving clear, friendly, and concise answers using only the retrieved context provided to you. Follow these rules strictly:\n",
    "\n",
    "                1. Answer Based Only on the Provided Context:\n",
    "                - If a specific answer to the question is in the context, use that information directly.\n",
    "                - If the context provides multiple possible answers, prompt the user for clarification by listing the available options.\n",
    "                - If no relevant information is available, say: \"I'm not sure about that, but you can find more information at the Highrise FAQ: https://support.highrise.game/en/\".\n",
    "\n",
    "                2. Be Concise and Friendly:\n",
    "                - Always end the response with a friendly phrase, such as \"Let me know if you need more help!\".\n",
    "\n",
    "                3. Ask for Clarification if Needed:\n",
    "                - If the user's question is unclear, respond with: \"Could you please clarify what you mean? I can assist with topics related to \" and also list the available options.\n",
    "                \"\"\"\n",
    "            \"\\n\\n\"\n",
    "            \"{context}\"\n",
    "        )\n",
    "    \n",
    "    # Create prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "    \n",
    "    # Initialize LLM and create chain\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    return create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: How can I delete my account?\n",
      "Answer: To permanently delete your Highrise account, you'll need the latest app version.  Open your profile, tap the gear icon, select 'Account Management', then 'Delete Your Account'.  Enter your Safety Lock (if enabled) and password to begin the process. You have 24 hours to cancel. After that, your account will be deactivated, and all data will be permanently deleted after 30 days.  Remember, deleting your account is irreversible!\n",
      "\n",
      "Let me know if you need more help!\n",
      "\n",
      "\n",
      "Question: What are inbox calls?\n",
      "Answer: Inbox Calls is a feature that lets you voice chat directly within Highrise, no matter where you are in the app.  You can make private 1:1 calls, join group calls, or participate in crew voice chats. Let me know if you need more help!\n",
      "\n",
      "\n",
      "Question: How do I report inappropriate behavior?\n",
      "Answer: To report inappropriate behavior in Highrise, you can use the in-app reporting tool.  The process varies slightly depending on what you're reporting (chat messages, voice chat, direct messages, newsfeed posts, newsfeed comments, or profiles).  The instructions for each are detailed in the provided text. Could you please clarify what you mean? I can assist with topics related to \"Chat Messages,\" \"Voice Chat,\" \"Direct Messages,\" \"Newsfeed Posts,\" \"Newsfeed Comments,\" or \"Profiles.\" Let me know if you need more help!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_chain = setup_retrieval_chain(vector_store)\n",
    "test_questions = [\n",
    "    \"How can I delete my account?\",\n",
    "    \"What are inbox calls?\",\n",
    "    \"How do I report inappropriate behavior?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    response = rag_chain.invoke({\"input\": question})\n",
    "    print(f\"Answer: {response['answer']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
